{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Profile Comparison\n",
    "\n",
    "Statistical comparison of AI profile performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "from dicee_analysis import (\n",
    "    load_games,\n",
    "    compare_profiles,\n",
    "    plot_profile_comparison,\n",
    "    plot_win_rates,\n",
    "    plot_bonus_rates,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "RESULTS_PATH = \"../../../results/games.ndjson\"\n",
    "games = load_games(RESULTS_PATH, progress=True)\n",
    "print(f\"Loaded {games.n_unique('game_id')} games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile Comparison Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison with confidence intervals\n",
    "fig = plot_profile_comparison(games, title=\"AI Profile Performance Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests\n",
    "\n",
    "Compare specific profile pairs using Welch's t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare professor vs carmen\n",
    "profiles = games[\"profile_id\"].unique().to_list()\n",
    "\n",
    "if len(profiles) >= 2:\n",
    "    result = compare_profiles(games, profiles[0], profiles[1])\n",
    "    print(f\"Comparing {profiles[0]} vs {profiles[1]}:\")\n",
    "    print(f\"  {result.conclusion}\")\n",
    "    print(f\"  p-value: {result.p_value:.4f}\")\n",
    "    print(f\"  Effect size: {result.effect_size:.3f} ({result.effect_interpretation})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise comparisons\n",
    "from itertools import combinations\n",
    "\n",
    "print(\"Pairwise Profile Comparisons (Welch's t-test):\\n\")\n",
    "print(f\"{'Profile 1':<12} {'Profile 2':<12} {'p-value':<10} {'Effect':<8} {'Significant'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for p1, p2 in combinations(profiles, 2):\n",
    "    result = compare_profiles(games, p1, p2)\n",
    "    sig = \"Yes\" if result.significant else \"No\"\n",
    "    print(f\"{p1:<12} {p2:<12} {result.p_value:<10.4f} {result.effect_size:<8.3f} {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Win Rates (for multiplayer games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only meaningful if games have multiple players\n",
    "n_players_per_game = games.group_by(\"game_id\").agg(pl.len().alias(\"n\"))[\"n\"].mean()\n",
    "\n",
    "if n_players_per_game > 1:\n",
    "    fig = plot_win_rates(games, title=\"Win Rates by Profile\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Single-player games - win rates not applicable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upper Bonus Achievement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_bonus_rates(games, title=\"Upper Bonus Achievement Rate\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
